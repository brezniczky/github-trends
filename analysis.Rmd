---
title: "A Language for Analytics and Algorithms (working draft)"
author: "Janca"
date: "23 December 2016"
output:
  md_document:
    toc: true
---

# A Language for Analytics and Algorithms (working draft)

## Executive Conjecture

Python.

## Introduction

Which language to choose for analytics? It can be hard to tell.

The competition of programming langauges is already a long story and continues to stretch on.
Judging the topic is difficult, subjective and is prone to statistical methodological issues.

This analysis is aimed at getting some indication of the trends, but by no means to come up with a definitive result or judgement over any debate.

The present version attempts to achieve even less - to be a starting point for the 
above. I had to do some manual scraping to get some results quickly, hopefully no error has been made, a more streamlined approach is to follow later.

The "methodology" was quite simple, I searched GitHub with keywords like Analysis and Spark on a yearly basis (as much as possible), and took a note of the results in csv's.

```{r echo=FALSE}

# setwd("/media/janca/Code/Prog/Github Analysis/analytics-and-hadoop-trends")

# read in data
library(knitr)
analysis_table = read.csv("input/analysis_trends.csv")
lang_table = read.csv("input/lang_trends.csv")
spark_table = read.csv("input/spark_trends.csv")
ml_table = read.csv("input/ml_trends.csv")
dl_data_table = read.csv("input/deep_learning_trends.csv")
dl_data_table$`C++` = dl_data_table$C..
big_data_table = read.csv("input/big_data_trends.csv")

# function for outputting data
format.data = function(counts, keyword, col) {
  barplot(counts, 
    main=sprintf('\'%s\' related repositories on Github', keyword),
    xlim = c(0, ncol(counts) * nrow(counts) + 9),
    xlab="Year of creation", 
    col=col,
   	legend.text = rownames(counts), 
    beside = TRUE,
    args.legend = (x=ncol(counts) + 3))
  
  kable(counts)
}

grab.columns = function(frame, names) {
  counts = t(cbind(frame[names]))
  colnames(counts) <- frame$Year
  return(counts)
}
```

## Keyword #1: "Analysis"

The most interesting here is probably that the influence of R seems to plateau out.

```{r echo=FALSE}
counts = grab.columns(analysis_table, c("R", "Python", "Java"))

format.data(counts, "Analysis", c("red", "darkblue", "green"))
```

For some, the likely surprise of the (currently fractional) year 2016 may also be that Python (at least in this aspect) seems to be overtaking the lead in being the prime vehicle for analytics from R. Beyond that, both are strong candidates and Python is obviously involved in more analysis related libraries than R (part of the perceived growth is that it is probably catching up), which is just one of the reasons to scratch our heads whether to accept such finding as a fact. However, probably not many are that surprised, and this is just what it is. The R ecosystem needs to pull itself together quick if it wants to achieve more than to see the Python train passing.

(Note that GitHub is a distorted representation - a large proportion of the repositories is simple coursework... but also mind that coursework is a good predictor of future preference.)

## Keyword #2: "Spark"

```{r echo=FALSE}
counts = grab.columns(spark_table, c("Python", "Java", "Scala"))

format.data(counts, "Spark", c("darkblue", "green", "red"))
```

Scala steadily seems to be the major player at Spark.
SparkR is in a pre-explosion state, if anywhere - and R didn't make it to the top 10 in any year.

However, looking at ItJobsWatch provides a slightly different result at the time writing, at least in the London context: Java and Apache Spark are more often colocated in job advertisements than Scala and Apache Spark. But! Java is big (30%) otherwise, some Spark users and thus teams will have a Hadoop background with a carried over Java preference, and not sure how much of its slight dominance would be left once we corrected for that.

See http://www.itjobswatch.co.uk/jobs/london/apache%20spark.do for the current status in case of interest.

Similarly GitHub for the past 6 months indicates a trendshift, too - however due to potential seasonality issues and overwhelming Christmas laziness that's not been presented here. Next version.


## Keyword #3: "Machine Learning"

```{r echo=FALSE}
counts <- grab.columns(ml_table, c("Python", "Java", "R"))

format.data(counts, "Machine Learning", c("darkblue", "green", "red"))
```

I think this one needs no explanation. In my experience, GitHub repos are quite often related to online learning, and the conclusion to draw is that Python is the de facto standard of choice for teaching machine learning. 

## Keyword #4: "Deep Learning"

```{r echo=FALSE}
counts <- grab.columns(dl_data_table, c("C++", "Java", "MatLab", "Python"))

format.data(counts, "Deep Learning", c("red", "green", "yellow", "darkblue"))
```


## +1: "Big Data"

```{r echo=FALSE}
counts <- grab.columns(big_data_table, c("Python", "Java", "R", "Scala"))

format.data(counts, "Big Data", col=c("darkblue", "green", "yellow", "red"))
```

## Conclusion

Python.

At the minute, it seems, if you only choose one programming language for analytics (however overly idealized that situation may be), or about to choose your first one, it is Python for the win.
It appears to be of significant presence (transferrable) or sheer dominance (hard to dismiss) in every single aspect examined above.
And you won't be alone with using it.
There are lots of things to work out in such an exploding ecosystem, and in the best case you're part of the happenings.
