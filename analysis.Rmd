---
title: "Analysis, spark, languages [Working draft]"
author: "Janca"
date: "23 December 2016"
output: html_document
---

# Introduction

Which language to choose for analytics? It can be hard to tell.

The competition of programming langauges is already a long story and continues to stretch on.
Judging the topic is difficult, subjective and is prone to statistical methdological issues.

This analysis is aimed at getting some indication of the trends, but by no means to come up with a definitive result or judgement over any debate.

The present version attempts to achieve even less - to be a starting point for the 
above. I had to do some manual scraping to get some results quickly, hopefully no error has been made, a more streamlined approach is to follow later.

```{r}
library(knitr)
# setwd("/media/janca/Code/Prog/Github Analysis/analytics-and-hadoop-trends")
analysis_table = read.csv("analysis_trends.csv")
lang_table = read.csv("lang_trends.csv")
spark_table = read.csv("spark_trends.csv")
```

## "Analysis"

```{r}
counts <- rbind(R=analysis_table$R, Python = analysis_table$Python, Java = analysis_table$Java)
colnames(counts) <- analysis_table$Year

barplot(counts, 
  main='\'Analysis\' related repositories on Github',
  xlim = c(0, ncol(counts) * nrow(counts) + 9),
  xlab="Year of creation", 
  col=c("darkblue","red", "green"),
 	legend.text = rownames(counts), 
  beside = TRUE,
  args.legend = (x=ncol(counts) + 3))

kable(counts)

```

For some, the likely surprise of the (currently fractional) year 2016 may be that Python (at leat in this aspect) seems to be overtaking the lead in being the prime vehicle for analytics from R. Beyond that, both are strong candidates and Python is obviously involved in more analysis related libraries than R, which is just one of the reasons to scratch our heads whether to accept such finding as a fact. However, probably not many are that surprised.

Note that GitHub is also a biased representation - a large proportion of the repositories is simple coursework.

## "Spark"

```{r}
counts <- rbind(Python = spark_table$Python, Java = spark_table$Java, Scala = spark_table$Scala)
colnames(counts) <- spark_table$Year

barplot(counts, 
  main='\'Spark\' related repositories on Github',
  xlim = c(0, ncol(counts) * nrow(counts) + 9),
  xlab="Year of creation", 
  col=c("darkblue","red", "green"),
 	legend.text = rownames(counts), 
  beside = TRUE,
  args.legend = (x=ncol(counts) + 3))

kable(counts)
```

Scala seems to be the major player with Spark.

