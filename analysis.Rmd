---
title: "Analysis, Spark, ML, Big Data vs. languages [Working draft]"
author: "Janca"
date: "23 December 2016"
output: html_document
---

# Introduction

Which language to choose for analytics? It can be hard to tell.

The competition of programming langauges is already a long story and continues to stretch on.
Judging the topic is difficult, subjective and is prone to statistical methodological issues.

This analysis is aimed at getting some indication of the trends, but by no means to come up with a definitive result or judgement over any debate.

The present version attempts to achieve even less - to be a starting point for the 
above. I had to do some manual scraping to get some results quickly, hopefully no error has been made, a more streamlined approach is to follow later.

The "methodology" was quite simple, I searched GitHub with keywords like Analysis and Spark on a yearly basis (as much as possible), and took a note of the results in csv's.

```{r}
library(knitr)
# setwd("/media/janca/Code/Prog/Github Analysis/analytics-and-hadoop-trends")
analysis_table = read.csv("input/analysis_trends.csv")
lang_table = read.csv("input/lang_trends.csv")
spark_table = read.csv("input/spark_trends.csv")
ml_table = read.csv("input/ml_trends.csv")
big_data_table = read.csv("input/big_data_trends.csv")
```

## "Analysis"

The most interesting here is probably that the influence of R seems to plateau out.

```{r}
counts <- rbind(R=analysis_table$R, Python = analysis_table$Python, Java = analysis_table$Java)
colnames(counts) <- analysis_table$Year

barplot(counts, 
  main='\'Analysis\' related repositories on Github',
  xlim = c(0, ncol(counts) * nrow(counts) + 9),
  xlab="Year of creation", 
  col=c("darkblue","red", "green"),
 	legend.text = rownames(counts), 
  beside = TRUE,
  args.legend = (x=ncol(counts) + 3))

kable(counts)

```

For some, the likely surprise of the (currently fractional) year 2016 may also be that Python (at leat in this aspect) seems to be overtaking the lead in being the prime vehicle for analytics from R. Beyond that, both are strong candidates and Python is obviously involved in more analysis related libraries than R, which is just one of the reasons to scratch our heads whether to accept such finding as a fact. However, probably not many are that surprised, and this is just what it is. The R ecosystem needs to pull itself together quick if it wants to achieve more than to see the Python train passing.

(Note that GitHub is a distorted representation - a large proportion of the repositories is simple coursework... but also mind that coursework is a good predictor of future preference.)

## "Spark"

```{r}
counts <- rbind(Python = spark_table$Python, Java = spark_table$Java, Scala = spark_table$Scala)
colnames(counts) <- spark_table$Year

barplot(counts, 
  main='\'Spark\' related repositories on Github',
  xlim = c(0, ncol(counts) * nrow(counts) + 9),
  xlab="Year of creation", 
  col=c("darkblue","red", "green"),
 	legend.text = rownames(counts), 
  beside = TRUE,
  args.legend = (x=ncol(counts) + 3))

kable(counts)
```

Scala steadily seems to be the major player at Spark.
SparkR is in a pre-explosion state, if anywhere - and R didn't make it to the top 10 in any year.

However, looking at ItJobsWatch provides a slightly different result at the time writing, at least in the London context: Java and Apache Spark are more often colocated in job advertisements than Scala and Apache Spark. But! Java is big (30%) otherwise, some Spark users and thus teams will have a Hadoop background with a carried over Java preference, and not sure how much of its slight dominance would be left once we corrected for that.

See http://www.itjobswatch.co.uk/jobs/london/apache%20spark.do for the current status in case of interest.

Similarly GitHub for the past 6 months indicates a trendshift, too - however due to potential seasonality issues and overwhelming Christmas laziness that's not been presented here. Next version.


## "Machine Learning"

```{r}
counts <- rbind(Python = ml_table$Python, Java = ml_table$Java, R = ml_table$R)
colnames(counts) <- spark_table$Year

barplot(counts, 
  main='\'Machine Learning\' related repositories on Github',
  xlim = c(0, ncol(counts) * nrow(counts) + 9),
  xlab="Year of creation", 
  col=c("darkblue","red", "green"),
 	legend.text = rownames(counts), 
  beside = TRUE,
  args.legend = (x=ncol(counts) + 3))

kable(counts)
```

I think this one needs no explanation. In my experience, GitHub repos are quite often related to online learning, and the conclusion to draw is that Python is the de facto standard of choice for teaching machine learning. 

## +1: "Big Data"

```{r}
counts <- rbind(Python = big_data_table$Python, Java = big_data_table$Java, R = big_data_table$R,
                Scala = big_data_table$Scala)
colnames(counts) <- spark_table$Year

barplot(counts, 
  main='\'Big Data\' related repositories on Github',
  xlim = c(0, ncol(counts) * nrow(counts) + 9),
  xlab="Year of creation", 
  col=c("darkblue","red", "green", "yellow"),
 	legend.text = rownames(counts), 
  beside = TRUE,
  args.legend = (x=ncol(counts) + 3))

kable(counts)
```

# Conclusion

At the minute, it seems, Python for the win.
It appears to be of significant presence or sheer dominance in every single aspect examined above.
